###############################################################################################
######################## JACNEx step 3: exon filtering and calling ############################
###############################################################################################
# Given a TSV of exon fragment counts produced by 1_countFrags.py
# It applies various continuous distributions from scipy's "continuous_distns" to
# normalized fragments counts of intergenic regions.
# See usage for more details.
###############################################################################################
import getopt
import logging
import matplotlib.pyplot
import matplotlib.backends.backend_pdf
import numpy as np
import os
import scipy.stats
import sys
from scipy.stats._continuous_distns import _distn_names
import time
import warnings

####### JACNEx modules
import countFrags.countsFile

# prevent PIL and matplotlib flooding the logs when we are in DEBUG loglevel
logging.getLogger('PIL').setLevel(logging.WARNING)
logging.getLogger('matplotlib').setLevel(logging.WARNING)

# set up logger, using inherited config, in case we get called as a module
logger = logging.getLogger(__name__)


###############################################################################
############################ PUBLIC FUNCTIONS ################################
###############################################################################

####################################################
# parseArgs:
# Parse and sanity check the command+arguments, provided as a list of
# strings (eg sys.argv).
# Return a list with everything needed by this module's main()
# If anything is wrong, raise Exception("EXPLICIT ERROR MESSAGE")
def parseArgs(argv):
    scriptName = os.path.basename(argv[0])

    # mandatory args
    countsFile = ""
    plotDir = "./plotDir/"

    usage = "NAME:\n" + scriptName + """\n
DESCRIPTION:
Given a TSV of intergenic fragment counts, identifies the best-fitting continuous distribution
based on R².
Finally, he provides a plot of the top 10 fits along with their associated parameters

ARGUMENTS:
    --counts [str]: TSV file, first 4 columns hold the exon definitions, subsequent columns
                    hold the fragment counts. File obtained from 1_countFrags.py.
    --plotDir [str]: sub-directory in which the graphical PDFs will be produced, default:  """ + plotDir + """
    -h , --help: display this help and exit\n"""

    try:
        opts, args = getopt.gnu_getopt(sys.argv[1:], 'h', ["help", "counts=", "plotDir="])
    except getopt.GetoptError as e:
        raise Exception(e.msg + ". Try " + scriptName + " --help")
    if len(args) != 0:
        raise Exception("bad extra arguments: " + ' '.join(args) + ". Try " + scriptName + " --help")

    for opt, value in opts:
        if (opt in ('-h', '--help')):
            sys.stderr.write(usage)
            sys.exit(0)
        elif (opt in ("--counts")):
            countsFile = value
        elif (opt in ("--plotDir")):
            plotDir = value
        else:
            raise Exception("unhandled option " + opt)

    #####################################################
    # Check that the mandatory parameter is present
    if countsFile == "":
        raise Exception("you must provide a counts file with --counts. Try " + scriptName + " --help.")
    elif (not os.path.isfile(countsFile)):
        raise Exception("countsFile " + countsFile + " doesn't exist.")

    # test plotdir last so we don't mkdir unless all other args are OK
    if not os.path.isdir(plotDir):
        try:
            os.mkdir(plotDir)
        except Exception as e:
            raise Exception("plotDir " + plotDir + " doesn't exist and can't be mkdir'd: " + str(e))

    # AOK, return everything that's needed
    return(countsFile, plotDir)


###############################################################################
############################ PRIVATE FUNCTIONS #################################
###############################################################################
############################
# bestFitContinuousDistribs
# allows from smoothed density data from observations to compute all continuous laws
# available in the scipy _distn_names library.
# Some laws have been suppressed because they do not work on the data used and other
# laws behave in the same way (frechet_l = weibullmax, frechet_r = weibullmin)
# the code is inspired by a discussion forum :
# https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python
# The continuous distributions with more than 3 parameters were also excluded
# for user-friendliness simplification
#
# Args:
# - data (list[float]): raw data in FPM
# - bins [int]: Number of bins for histogram.
#
# return:
# - best_distributions (list of lists): list of lists containing
#                                       [DISTRIBNAME,[PARAMS],[PDF], SSE, RSQUARED],
#                                       ordered by rsquared
def bestFitContinuousDistribs(data, bins):
    # Get histogram of original data
    y, x = np.histogram(data, bins=bins, density=True)
    x = (x + np.roll(x, -1))[:-1] / 2.0

    # Initialize output lists
    best_distributions = []

    # Estimate distribution parameters from data
    for ii, distribution in enumerate([d for d in _distn_names if d not in ['levy_stable', 'studentized_range', 'frechet_l', 'frechet_r']]):
        # Use getattr() to obtain the corresponding statistical distribution object from the scipy.stats module
        distribution = getattr(scipy.stats, distribution)

        # Try to fit the current distribution
        try:
            # Ignore warnings from data that can't be fit
            with warnings.catch_warnings():
                warnings.filterwarnings('ignore')
                # Compute distribution parameters from raw data, usually containing loc and scale,
                # but could have additional parameters
                params = distribution.fit(data)

                # Skip distributions with more than 3 parameters
                if len(params) > 3:
                    logger.info("{:>3} / {:<3}: {} NOT FIT: num args > 3".format(ii + 1, len(_distn_names), distribution.name))
                    continue

                # Separate parts of parameters
                arg = params[:-2]
                loc = params[-2]
                scale = params[-1]

                # Calculate fitted PDF and error with fit in distribution
                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)

                #######
                # compute quality fitting scores
                y_mean = np.mean(y)
                ss_tot = np.sum((y - y_mean)**2)

                # Calculate SSE (Sum of Squared Errors)
                sse = np.sum((y - pdf)**2)

                # Calculate R-squared
                r_squared = 1 - sse / ss_tot

                if np.isnan(r_squared):
                    logger.info("{:>3} / {:<3}: {} NOT FIT: nan r² score".format(ii + 1, len(_distn_names), distribution.name))
                else:
                    best_distributions.append((distribution, params, pdf, sse, r_squared))
                    logger.info("{:>3} / {:<3}: {} params:{}; sse:{}; r²:{}".format(ii + 1, len(_distn_names), distribution.name, params, sse, r_squared))

        except Exception as e:
            logger.info("{:>3} / {:<3}: {} NOT FIT: {}".format(ii + 1, len(_distn_names), distribution.name, e))
            continue

    return sorted(best_distributions, key=lambda x: x[4], reverse=True)


########################
# plotDistrib
# Plots real data and best-fit probability distributions on the same graph.
#
# Args:
# - intergenicVec (list[float]): data points
# - userBins (int): Number of bins for histogram.
# - distributions (list): best-fit distributions to be plotted.
# - plotFile (str): Path to the output PDF file where the plot will be saved.
# - NBBestFit (int): Number of top best-fit distributions to include in the plot.
def plotDistrib(intergenicVec, userBins, distributions, plotFile, NBBestFit):
    # Select the top NBBestFit distributions
    top = distributions[:NBBestFit]

    # Create a PDF file for the plot
    pdfFile = matplotlib.backends.backend_pdf.PdfPages(plotFile)
    fig = matplotlib.pyplot.figure(figsize=(16, 12))

    # Plot the real data as a histogram
    n, bins, patches = matplotlib.pyplot.hist(intergenicVec,
                                              bins=userBins,
                                              density=True,
                                              alpha=0.2,
                                              color='blue',
                                              label="Real Data")
    # Plot the best-fit distribution
    for i in range(len(top)):
        label = str(top[i][0].name)
        matplotlib.pyplot.plot(bins[:-1],
                               top[i][2],
                               label=f'{label} r²={np.round(top[i][4], 2)}',
                               linewidth=3.0,
                               linestyle='--')

    matplotlib.pyplot.legend()
    matplotlib.pyplot.ylabel("Densities")
    matplotlib.pyplot.xlabel("FPMs")
    pdfFile.savefig(fig)
    pdfFile.close()


###############################################################################
############################ PUBLIC FUNCTIONS #################################
###############################################################################
####################################################
# main function
# Arg: list of strings, eg sys.argv
# If anything goes wrong, raise Exception("SOME EXPLICIT ERROR MESSAGE"), more details
# may be available in the log
def main(argv):
    # parse, check and preprocess arguments
    (countsFile, plotDir) = parseArgs(argv)

    # args seem OK, start working
    logger.debug("called with: " + " ".join(argv[1:]))
    logger.info("starting to work")
    startTime = time.time()

    ###################
    # parse and FPM-normalize the counts, distinguishing between exons and intergenic pseudo-exons
    try:
        (samples, autosomeExons, gonosomeExons, intergenics, autosomeFPMs, gonosomeFPMs,
         intergenicFPMs) = countFrags.countsFile.parseAndNormalizeCounts(countsFile)
    except Exception as e:
        logger.error("Failed to parse and normalize counts for %s: %s", countsFile, repr(e))
        raise Exception("Failed to parse and normalize counts")

    thisTime = time.time()
    logger.debug("Done parsing and normalizing counts file, in %.2f s", thisTime - startTime)
    startTime = thisTime

    #################
    # preparing data for fit
    ######
    # Dev user params
    # limitation of samples number to be processed because the process is very long
    # aproximately 11min for 168,000 intergenic regions (= one sample from ensembl)
    NBSampsToProcess = 1
    userBins = 100
    NBBestFit = 10
    plotFile1 = os.path.join(plotDir, str(NBBestFit) + "_bestContinuousDistrib_" + str(userBins) + "bins_" + str(NBSampsToProcess) + "samps.pdf")
    plotFile2 = os.path.join(plotDir, str(NBBestFit) + "_bestContinuousDistrib_" + str(userBins) + "bins_" + str(len(samples)) + "samps.pdf")
    plotFile3 = os.path.join(plotDir, str(NBBestFit) + "_bestContinuousDistrib_Only2params_" + str(userBins) + "bins_" + str(NBSampsToProcess) + "samps.pdf")
    plotFile4 = os.path.join(plotDir, str(NBBestFit) + "_bestContinuousDistrib_Only2params_" + str(userBins) + "bins_" + str(len(samples)) + "samps.pdf")

    # Generate random indexes for the columns
    randomSampInd = np.random.choice(intergenicFPMs.shape[1], NBSampsToProcess, replace=False)
    sampleNames = ' '.join([samples[index] for index in randomSampInd])
    logger.info(f"samples analysed: {sampleNames}")

    # Select the corresponding columns intergenicFPMs
    randomCountsArray = intergenicFPMs[:, randomSampInd]

    # reshaping (e.g., -1 to keep the number of rows)
    vec = randomCountsArray.reshape(intergenicFPMs.shape[0], -1)

    # for plotting we don't care about large counts (and they mess things up),
    # we will only consider the bottom fracDataForSmoothing fraction of counts, default
    # value should be fine
    fracDataForSmoothing = 0.99
    # corresponding max counts value
    maxData = np.quantile(vec, fracDataForSmoothing)
    intergenicVec = vec[vec <= maxData]

    #####################
    # fitting continuous distributions
    try:
        distributions = bestFitContinuousDistribs(intergenicVec, userBins)
    except Exception as e:
        raise Exception("bestFitContinuousDistribs failed: %s", repr(e))

    thisTime = time.time()
    logger.debug("Done fitting continuous distributions on intergenic counts, in %.2f s", thisTime - startTime)
    startTime = thisTime

    #####################
    # Plot 
    # Define a list of data and corresponding plot files
    data_files = [
        (intergenicVec, plotFile1),
        (intergenicFPMs.reshape(-1), plotFile2),
        (intergenicVec, plotFile3),
        (intergenicFPMs.reshape(-1), plotFile4)
    ]

    # Define the list of distributions to use
    topDistrib_2params = []
    for di in distributions:
        if len(di[2]) <= 2:
            topDistrib_2params.append(di)

    distributions_to_use = [distributions, distributions, topDistrib_2params, topDistrib_2params]

    # Iterate through the data files and distributions
    for i, (data, plot_file) in enumerate(data_files):
        try:
            plotDistrib(data, userBins, distributions_to_use[i], plot_file, NBBestFit)
        except Exception as e:
            raise Exception(f"Failed to plot distributions for plotFile{i+1}: {repr(e)}")


    thisTime = time.time()
    logger.debug("Done plotting best distributions in %.2f s", thisTime - startTime)
    logger.info("Process completed")


####################################################################################
######################################## Main ######################################
####################################################################################
if __name__ == '__main__':
    scriptName = os.path.basename(sys.argv[0])
    # configure logging, sub-modules will inherit this config
    logging.basicConfig(format='%(asctime)s %(levelname)s %(name)s: %(message)s',
                        datefmt='%Y-%m-%d %H:%M:%S',
                        level=logging.DEBUG)
    # set up logger: we want script name rather than 'root'
    logger = logging.getLogger(scriptName)

    try:
        main(sys.argv)
    except Exception as e:
        # details on the issue should be in the exception name, print it to stderr and die
        sys.stderr.write("ERROR in " + scriptName + " : " + str(e) + "\n")
        sys.exit(1)
